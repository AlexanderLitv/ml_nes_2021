{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1.\n",
    "Предположим, мы решаем задачу классификации на три класса по двум признакам и используем метод k ближайших соседей с k=3 и манхэттанской метрикой. Мы имеем следующую обучающую выборку:\n",
    "\n",
    "| Признак 1 | Признак 2 | Класс |\n",
    "|-----------|-----------|-------|\n",
    "| 1         | -1        | 1     |\n",
    "| 2         | 2         | 1     |\n",
    "| 3         | 2         | 2     |\n",
    "| 1         | 0         | 3     |\n",
    "| 2         | -2        | 3     |\n",
    "\n",
    "Каковы будут предсказания для объекта $x=(2, -1)$?\n",
    "\n",
    "#### Задача 2.\n",
    "Визуализируйте разделяющую поверхность между классами для следующей выборки:\n",
    "\n",
    "| Признак 1 | Признак 2 | Класс |\n",
    "|-----------|-----------|-------|\n",
    "| 2         | 2        | 1     |\n",
    "| 3         | 2         | 1     |\n",
    "| 2         | 0         | 2     |\n",
    "| 1         | -1         | 3     |\n",
    "| 1        | 1        | 3     |\n",
    "\n",
    "Используйте k=1 и евклидово расстояние.\n",
    "\n",
    "__Решение.__\n",
    "\n",
    "В задачах классификации с двумя признаками мы можем изобразить признаковое пространство на плоскости и раскрасить его в разные цвета в соответствии с классом каждой точки плоскости. В этом и состоит сейчас наша задача.\n",
    "\n",
    "Для начала отобразим на плоскости обучающую выборку - пять точек - в соответствии с их координатами.\n",
    "\n",
    "При $k=1$ каждая точка плоскости будет относиться к тому же классу, что и ближайший к ней объект обучающей выборки. Если нам даны две точки разных классов, то чтобы провести между ними границу классов, нужно построить серединный перпендикудяр. Для случая с несколькими точками нужно построить несколько серединных перпендикуляров, найти их точки пересечения и определить, какие области к каким классам относятся. Более строго такая конструкция задается с помощью [Диаграммы Вороного](https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%B0%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0_%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D0%BE%D0%B3%D0%BE), но мы не будем вдаваться в ее детали.\n",
    "\n",
    "<div>\n",
    "<img src=\"classifi.png\" width=\"350\"/>\n",
    "</div>\n",
    "\n",
    "#### Задача 3.\n",
    "Предположим, мы решаем задачу регрессии по двум признакам и используем метод k ближайших соседей с k=3 и манхэттанской метрикой. Мы имеем следующую обучающую выборку:\n",
    "\n",
    "| Признак 1 | Признак 2 | Ответ |\n",
    "|-----------|-----------|-------|\n",
    "| 1         | -1        | 3.5     |\n",
    "| 2         | 2         | 2.3     |\n",
    "| 3         | 2         | 1.7     |\n",
    "| 1         | 0         | -0.4     |\n",
    "| 2         | -2        | 0.1     |\n",
    "\n",
    "Каковы будут предсказания для объекта $x=(2, -1)$?\n",
    "\n",
    "#### Вопрос: каковы параметры и гиперпараметры метода kNN?\n",
    "\n",
    "#### Вопрос: какова динамика качества работы kNN при увеличении k?\n",
    "\n",
    "__Ответ:__\n",
    "\n",
    "При $k=1$ вокруг каждого объекта обучающей выборки создается область его класса. Если, к примеру, в \"большую\" область одного класса случайно попал один шумовой объект другого класса, вокруг этого шумового объекта будет \"остров\" предсказания другого класса. Это нелогично и говорит о переобучении.\n",
    "\n",
    "При $k$, равном числу объектов в выборке, для всех объектов будет предсказываться одно и то же, что вновь говорит о низком качестве работы классификатора. Получается, что качество kNN при увеличении $k$ должно сначала расти, а потом падать, и оптимум будем где-то посередине.\n",
    "\n",
    "Рассмотрим синтетический пример: на рисунке визуализирована обучающая выборка (\"настоящая\" разделяющая поверхность - прямая) и разделяющая поверхность kNN по аналогии с задачей 2, и на разных графиках используется разное число соседей $k$:\n",
    "\n",
    "<div>\n",
    "<img src=\"k_grid.png\" width=\"550\"/>\n",
    "</div>\n",
    "\n",
    "При использовании малых $k$ разделяющая поверхность слишком сложная, на нее оказывают сильное воздействие шумовые объекты. Далее поверхность становится все ровнее и ровнее и при $k=50$ выглядит наиболее разумно. При большем k разделяющая поверхность уходит от линейной, и оранжевый класс \"захватывает\" синий.\n",
    "\n",
    "#### Вопрос: почему при использовании kNN важно нормировать данные?\n",
    "\n",
    "### Практическая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# изображения цифр\n",
    "from sklearn.datasets import load_digits\n",
    "# классификатор\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# шаффлер данных\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируйте классификатор с дефолтным числом соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = # code\n",
    "\n",
    "data = load_digits()\n",
    "X = data.images\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вытягиваем квадратное изображение в вектор, чтобы получить матрицу объекты-признаки\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# перемешиваем данные\n",
    "X, y = shuffle(X, y)\n",
    "print(f\"Features shape: {X.shape},\\nTarget shape: {y.shape}\")\n",
    "print(f\"Target samples: {y[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:700, :], y[:700]\n",
    "X_val, y_val = X[700:1300, :], y[700:1300]\n",
    "X_test, y_test = X[1300:, :], y[1300:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите классификатор и сделайте предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте долю правильных ответов (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать разные значения гиперпараметра k. Сравнивать разные значения k по обучающей выборке бесполезно: каждый объект является ближайшим сам к себе и оптимальное k будет равно 1. Будем сравнивать разные k по качеству на валидационной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор k на валидационной выборке:\n",
    "for k in range(1, 20):\n",
    "    y_predicted = # code for prediction\n",
    "    print(f\"k = {k}; accuracy = {np.mean(y_train==y_predicted):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним точность (accuracy) на обучении, валидации и тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "for X_data, y_data in zip([X_train, X_val, X_test], [y_train, y_val, y_test]):\n",
    "    y_predicted = clf.predict(X_data)\n",
    "    print(f\"Accuracy: {np.mean(y_predicted==y_data):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
